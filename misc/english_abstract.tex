
\begin{englishabstract}
	Benefited from the rapid development of machine vision and natural language processing brought by neural networks, Visual Question Answering(VQA) is a popular research direction in the field of artificial intelligence in recent years. VQA is a task that outputs the answer to the question given a picture and a natural language question related to the image. Although the complexity of the image content and the open-ended form of the question make the task full of challenges, it is closer to general artificial intelligence than the other tasks and has high research value and broad applications. The models proposed can be generally divided into two types: joint embedding models and Knowledge Base(KB)-based models according to whether the external knowledge base is involved. In this paper, we will address these two types perspectively. We first overviewed past related researches, including VQA models, datasets and knowledge bases. To improve past joint embedding models, which all used static word vectors, we proposed to use dynamic word vectors, combining Faster R-CNN and attention mechanism to construct the None KB-Specific Network (N-KBSN) model. To further improve the accuracy of the model, we first proposed to introduce the graph embedding of the knowledge base to the N-KBSN model, the KBSN model was constructed. Experimental results on several datasets show that the improved dynamic word vectors can provide better text features, and the introduction of knowledge base graph embedding also significantly improves the accuracy of the results. In addition, we also created two knowledge bases dbv and dba with rich semantics extracted from DBpedia. These two knowledge bases can be the basis for future research on the embedding of knowledge base graphs.
	
	\englishkeyword{Visual Question Answering, Joint Embedding Model, Knowledge Base, N-KBSNï¼ŒKBSN}
\end{englishabstract}


