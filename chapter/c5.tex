\chapter{全文总结及展望}
\section{全文总结}
本文的研究内容是视觉问答模型的构建，其中重点研究了联合嵌入模型和知识库嵌入模型两类。针对已有联合嵌入模型在文本特征化方面的缺陷，本文构建了基于动态词向量的联合嵌入模型（N-KBSN）。实验结果证明了动态词向量的引入能显著的提高视觉问答模型的准确率。进一步，为解决联合嵌入模型固有的网络容量小等缺陷，在N-KBSN的基础上，本文构建了知识库图嵌入模块，提出了KBSN模型。实验证明知识库图嵌入模型能一定程度地提高预测准确率，在面对复杂问题时效果尤其好。

（1）首先，本文介绍了视觉问答任务和模型架构。本文对视觉问答任务中的问题类型和数据集进行了分类，根据问题回答是否需要常识或外源知识，划分出基于视觉的数据集和基于知识的数据集，并在之后的实验中使用了这两类数据集。视觉问答模型架构一般包括特征提取、注意力机制、特征融合、答案生成等模块。针对已有模型的问题，文本首先改进了文本特征提取部分，之后又引入了知识库图嵌入模块。

（2）本文改进了联合嵌入模型的文本特征化方法，构建了N-KBSN模型。现有模型均使用“静态词向量+LSTM”完成文本特征提取，这种结构无法有效表征一词多义和一词多成分的情况。为了提高文本的表征能力，N-KBSN模型使用了一个预训练的双层biLSTM模型，以获得能感知上下文的动态词向量。在使用VQA2.0的视觉问答实验中，本文构建和测试了一系列基于静态词向量和使用不同参数配置的动态词向量模型。实验结果显示，在模型其他部分相同的情况下，基于动态词向量的模型准确率均明显高于静态词向量模型，并且biLSTM的网络越深，准确率提升效果越好。本文还使用定量分析和定性分析解释了N-KBSN优秀性能的原因。

（3）在N-KBSN模型基础上，本文添加了知识图嵌入模块，构建了KBSN模型。知识图嵌入模块由知识库子图提取和知识库子图嵌入两部分组成，其中子图提取部分使用Faster R-CNN和spotlight模型分别从图像和文本中识别关键实体，并从知识库中提取核心实体相关联的子图。为构建子图嵌入模块，本文进行了知识库嵌入实验。实验使用的数据集是本文从DBpedia知识库提取的两个实验知识库：DBV和DBA。实验结果证明TransE模型在DBV知识库上的嵌入效果最好，因此本文最终使用TransE模型作为KBSN的知识库子图嵌入模块。本文使用VQA2.0和KB-VQA两个数据集训练和测试了KBSN模型，实验结果证明知识库图嵌入模块能提高模型的准确率，并且在面对需要常识或者外源知识的问题时，其能显著提高模型的准确率。

\section{后续工作展望}
本文改进的两个视觉问答模型均在视觉问答数据集上取得较好的准确率，但并没有达到当前最佳，仍有一定的改进和提升空间。

（1）图像特征化方法

由于图像特征化方法并不是本文的研究内容，因此本文直接使用预训练的Faster R-CNN网络提取图像特征，参数的设计也是迁移了2017年VQA挑战的冠军模型\citing{teney2018tips}，仅仅在训练中微调参数。如果要进一步提升模型的准确率，一方面，可以进行网络搜索获得最佳的超参数组合，另一方面，可以使用效果更好的图像识别模型如Mask R-CNN。

（2）子图提取方法的改进

本文使用的知识库子图提取的基本思路是：先从图像和问题文本中提取核心实体，再从知识库中提取出以核心实体为中心的子图。这种方法仅仅关注了三元组数据的主语，能减少搜索量。但是贪婪的提取方式必然会引入噪音，从而影响性能。因此以后的工作可以改进子图提取方法，例如建立图像核心实体和文本核心实体的关联，裁剪子图无关连接，考虑核心实体在谓语和宾语的情况。

（3）知识库的建立

本文基于DBpedia构建了两个知识库：DBV和DBA。根据知识库嵌入实验可知，虽然DBA有更大的数据量，但模型在其上的链路预测准确率并不高，这说明了DBA知识库很难得到优秀的嵌入表示。但即使是准确率最高的DBV知识库，TransE的准确率也不及70\%，这显然成为了后续知识库嵌入的瓶颈。因此后续的工作一方面可以建立语义对应性更强的知识库，另一方面可以试验更好的知识库嵌入方法，例如图神经网络。

（4）基于知识的数据集的丰富

本文使用了KB-VQA数据集，其中包含需要常识或外源知识的问题。从KBSN在VQA2.0和KB-VQA的实验结果可以看出，基于知识的数据集对模型推理和引用外源知识的要求更高，能更全面的衡量模型的推理能力。但是目前基于知识的数据集普遍面临的问题有数据集的标准不统一、数据量相对较小。因此增加数据量和丰富数据多样性是未来的研究方向之一。

